{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niall Carbery 22380966\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the best kernel? (Common options include a linear kernel, an RBF kernel)\n",
    "2. What are the metrics of successful classification?\n",
    "3. What is the minimum amount of the training data subset should you allocate for a successful classification?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./Homework_Datasets/o2Saturation.csv\")\n",
    "df = pd.read_csv('./Homework_Datasets/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable X to the features of the dataframe and y to the target column.\n",
    "X = df.drop('output', axis=1)\n",
    "y = df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the scaler fitted on the training data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  8]\n",
      " [ 8 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        41\n",
      "           1       0.84      0.84      0.84        50\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.82      0.82      0.82        91\n",
      "weighted avg       0.82      0.82      0.82        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit a SVC model\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Make predictions on the test data\n",
    "svc_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of parameters to search\n",
    "params_grid = {\n",
    "    'C': [0.05, 0.1, 0.5, 1, 10],\n",
    "    'kernel': ['poly','linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create an SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Define a GridSearchCV to search the best parameters\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = params_grid, \n",
    "                           scoring='f1',\n",
    "                           cv = 5, verbose = 1)\n",
    "\n",
    "# Search the best parameters with training data\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing over our datatsets we find that the linear SVC provides us with the best results, this would suggest that the data is linearly seperable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  9]\n",
      " [ 8 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        41\n",
      "           1       0.82      0.84      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retraining an SVC model with the best parameters\n",
    "best_svc = SVC(C=0.1, kernel='linear')\n",
    "best_svc.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Make predictions on the test data\n",
    "svc_pred = best_svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics of a succesful classification are accruacy, precision, recall, F1-score and support.\n",
    "- Accuracy measures the proportion of correctly classified instances out of the total predictions.\n",
    "\n",
    "- Precision focuses on the true positive predictions among all positive predictions.\n",
    "It’s useful when false positives are costly.\n",
    "\n",
    "- Recall measures the proportion of actual positive instances correctly predicted by the model.\n",
    "It’s essential when false negatives are costly.\n",
    "\n",
    "- The F1-score balances precision and recall.\n",
    "It’s the harmonic mean of precision and recall\n",
    "\n",
    "- Support refers to the number of instances (data points) in each class. It provides insights into the distribution of data across different classes.\n",
    "Support for the positive class represents the number of positive instances.\n",
    "Support for the negative class represents the number of negative instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum amount of training data required for successful classification depends on several factors, including the complexity of the problem, the quality of the data, and the chosen machine learning algorithm. \n",
    "- A common rule of thumb is to allocate at least 70% of your data for training and the remaining 30% for testing (validation or holdout set).\n",
    "This split helps ensure that the model learns from a substantial portion of the data while having unseen examples for evaluation.\n",
    "- If you have a small dataset, use cross-validation.\n",
    "Techniques like k-fold cross-validation (where the data is split into k subsets) allow you to train and evaluate the model on different subsets iteratively.\n",
    "In such cases, the training data subset can be even smaller (e.g., 50% or less).\n",
    "- For complex models (e.g., deep neural networks), more data is generally beneficial.\n",
    "Deep learning models often require large amounts of data to learn intricate features.\n",
    "\n",
    "- Consider the domain-specific requirements.\n",
    "Some domains (such as medical diagnosis) may demand larger datasets due to the rarity of certain conditions.\n",
    "\n",
    "- Machine learning is an iterative process.\n",
    "Its standard to start with a reasonable subset, evaluate the model, and gradually increase the data size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
